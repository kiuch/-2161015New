import pandas as pd
import MeCab
from collections import Counter
import matplotlib.pyplot as plt
import os
import numpy as np


# è¤‡æ•°ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®è¨­å®š (ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šã®çµ¶å¯¾ãƒ‘ã‚¹ã‚’å«ã‚€)
file_config = [
    {'title': 'SV', 'path': r'C:\Users\masat\OneDrive\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\deep learning\ãƒ‘ãƒ¯ãƒ\-2161015New\SVãƒ¬ãƒ“ãƒ¥ãƒ¼æ–‡.csv', 'review_col': 'ãƒ¬ãƒ“ãƒ¥ãƒ¼'},
    {'title': 'å‰£ç›¾', 'path': r'C:\Users\masat\OneDrive\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\deep learning\ãƒ‘ãƒ¯ãƒ\-2161015New\å‰£ç›¾ã‚·ãƒŠãƒªã‚ªæ–‡.csv', 'review_col': 'ã‚·ãƒŠãƒªã‚ªä¸€æ–‡'},
    {'title': 'USUM', 'path': r'C:\Users\masat\OneDrive\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\deep learning\ãƒ‘ãƒ¯ãƒ\-2161015New\sm_usumã‚·ãƒŠãƒªã‚ªæ–‡.csv', 'review_col': 'ã‚·ãƒŠãƒªã‚ªæ–‡'}
]

# ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ (å½¢æ…‹ç´ è§£æå¾Œã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ä½¿ç”¨)
stop_words = {
    "ã“ã®", "ã®", "ã¯", "ãŒ", "ã«", "ã‚’", "ã¨", "ã¦", "ãŸ", "ã ", "ã—", "ã‚‚ã£ã¨", "ã‚‚", "ã§ã™", "ã¾ã™", "ã‘ã©", "ã ã‚", "ãã‚Œ", 
    "ã„ã†", "ã‚ã‚‹", "ã‚‚ã®", "ãªã‚‹", "ã™ã‚‹", "ã„ã‚‹", "ã“ã¨", "ãªã„", "ã§ãã‚‹", "ãŸã‚", "ããƒ", "ã‚‰ã‚Œã‚‹", "ã‚Œã‚‹", "ã“ã‚Œ", 
    "ã‚¹ãƒ«", "ã‚¤ãƒ«", "ã‚¤ã‚¦", "ã‚¢ãƒ«", "ãƒŠãƒ«", "ãƒŠã‚¤", "ã‚³ãƒˆ", "ãƒ‡ã‚­ãƒ«", "ã‚·ãƒ¬ãƒ«", "ã‚«ãƒ³ã‚ºãƒ«", "ãƒ¢ãƒ",
    "ã‚²ãƒ¼ãƒ ", "ã‚·ãƒªãƒ¼ã‚º", "ãƒã‚±ãƒ¢ãƒ³",  "ãƒ›ãƒ³ã‚µã‚¯", "ãƒ«ãƒ¼ãƒˆ", "ãƒ–ãƒ–ãƒ³", 
    "ãƒ¬ãƒ™ãƒ«", "ã‚¿ãƒ¡", "ã‚½ãƒ", "ã‚»ã‚¤ãƒªãƒ„", "ãƒˆã‚ªã‚¯", "ãƒŸã‚¨ãƒ«", "ãƒãƒ„", "ã‚¤ã‚¯", "ã‚¯ãƒ«", "ã‚ªã‚¯",
    "ãƒ›ã‚«ã‚¯", "ã‚·ãƒ¥ãƒ«ã‚¤", "ãƒãƒ", "ã‚¤ãƒ", "ã‚¢ã‚¿ãƒª", "ãƒã‚¢ã‚¤", "ã‚¸ãƒ ", "ãƒ†ãƒ©ã‚¹ã‚¿ãƒ«", "è¦ç´ ", "ã‚·ã‚¹ãƒ†ãƒ ", 
    "æ„Ÿæƒ³", "ç‚¹", "éƒ¨åˆ†", "ä»Šå›",  "æ„Ÿã˜", "æ€ã£ãŸ", "ã¨ã“ã‚", "ã¾ãŸ",
    "ã‚­ãƒ£ãƒ©" 
}
positive_words = {
    "ç´ æ™´ã‚‰ã—ã„", "æ„Ÿå‹•çš„", "æœ€é«˜", "åä½œ", "é¢ç™½ã„", "è‰¯ã„", "è‰¯ã‹ã£ãŸ", "å¥½ã", 
    "æ³£ã", "ç¥", "æ¥½ã—ã„", "æœŸå¾…", "ç†±ã„", "ã‚«ãƒ¯ã‚¤ã‚¤", "ãƒ„ãƒŠã‚¬ãƒ«", "ç§€é€¸", "æ–°é®®", 
    "éš›ç«‹ã¤", "å®Œæˆåº¦", "ãƒãƒƒãƒ", "ç†±ä¸­", "å¼•ãè¾¼ã¾ã‚Œã‚‹", "å‚‘ä½œ", "è¦‹äº‹", "ãƒ¯ã‚¯ãƒ¯ã‚¯", 
    "æ„›ç€", "æ„›ã—ã„", "ç´å¾—", "ã—ã£ã‹ã‚Š", "æº€è¶³", 
    "æœ€é«˜å³°", "çµ‚ç›¤", "æ³£ã‘ã‚‹", "æœŸå¾…ä»¥ä¸Š"
}
negative_words = {
    "å¼±ã„", "å¹³å‡¡", "æ®‹å¿µ", "é™³è…", "æœ€æ‚ª", "ã‚¹ãƒˆãƒ¬ã‚¹", "è©•ä¾¡ã§ããªã„", "å¾®å¦™", 
    "ã¤ã¾ã‚‰ãªã„", "ä¸æº€", "æ‚ªã„", "ã‚ªã‚¯ãƒ¬", "ã‚¯ã‚½", "ãƒ¢ãƒ³ãƒ€ã‚¤", "ãƒ ãƒªãƒ§ã‚¦", "ã‚½ã‚¬ã‚¤", 
    "ãƒ¡ãƒ³ãƒ‰ã‚¦", "ã‚µã‚¤ã‚¢ã‚¯", "ã‚³ãƒ³ãƒŠãƒ³", "ãƒ¯ãƒ«ã‚¤", "ãƒŠãƒ³ã‚¤", "æ‹™ã•", "ç‰©è¶³ã‚Šãªã„", 
    "æœŸå¾…å¤–ã‚Œ", "å˜èª¿", "ä¸å¿«æ„Ÿ", "æ„å‘³ä¸æ˜", "è–„ã„", "é€€å±ˆ", "ç¨šæ‹™", "å°»ã™ã¼ã¿", 
    "ä¸å®Œå…¨", "æµ…ã„", "èª¬æ•™è‡­ã„", "æœ€ä½"
}

try:
    mecab = MeCab.Tagger() 
except Exception as e:
    print(f" MeCabã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    exit()

plt.rcParams['font.family'] = 'Meiryo' 
plt.rcParams['font.size'] = 12


def force_read_csv(file_path):
    encodings_to_try = ['utf-8', 'shift_jis', 'cp932', 'euc-jp']
    for encoding in encodings_to_try:
        try:
            df = pd.read_csv(file_path, encoding=encoding)
            return df
        except Exception:
            continue
    try:
        df = pd.read_csv(file_path, encoding='utf-8', errors='ignore')
        return df
    except Exception:
        return None

def unify_words(word):
    if word == 'ã‚­ãƒ£ãƒ©':
        return 'ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼'
    return word

def preprocess_text(text, mecab_tagger):
    words = []
    if not isinstance(text, str) or len(text) < 2:
        return []
    target_hinshi = ('åè©', 'å‹•è©', 'å½¢å®¹è©', 'æ„Ÿå‹•è©')
    try:
        node = mecab_tagger.parseToNode(text)
    except Exception:
        return []
    while node:
        features = node.feature.split(',')
        hinshi = features[0]
        original_form_for_check = node.surface
        if len(features) >= 7 and features[6] != '*':
            original_form_for_check = features[6]
        surface_form = node.surface
        
        if hinshi in target_hinshi and original_form_for_check not in stop_words and len(surface_form) > 1:
            processed_word = unify_words(surface_form) 
            words.append(processed_word)
        node = node.next
    return words

def analyze_sentiment(words):
    positive_score = sum(1 for word in words if word in positive_words)
    negative_score = sum(1 for word in words if word in negative_words)
    
    if positive_score > negative_score:
        sentiment = 'Positive'
    elif negative_score > positive_score:
        sentiment = 'Negative'
    else:
        sentiment = 'Neutral'
        
    return sentiment, positive_score, negative_score

def plot_sentiment_distribution(df_data, file_name, title): 
    """æ„Ÿæƒ…æ¥µæ€§ã®åˆ†å¸ƒã‚’å††ã‚°ãƒ©ãƒ•ã§å¯è¦–åŒ–ã™ã‚‹ (è‰²ã®å¯¾å¿œã‚’å›ºå®š)"""
    fixed_order = ['Positive', 'Negative', 'Neutral'] 
    colors = ['#66b3ff', '#ff9999', '#99ff99'] # é’=Positive, èµ¤=Negative, ç·‘=Neutral
    
    sentiment_counts = df_data['Sentiment'].value_counts().reindex(fixed_order, fill_value=0) 
    
    if not sentiment_counts.empty:
        plt.figure(figsize=(6, 6))
        plt.pie(
            sentiment_counts, 
            labels=sentiment_counts.index, 
            autopct='%1.1f%%', 
            startangle=90, 
            colors=colors 
        )
        plt.title(title)
        plt.tight_layout()
        plt.savefig(file_name)
        plt.close()

def main():
    print("ğŸš€ ä½œå“åˆ¥ æ„Ÿæƒ…åˆ†æã‚’é–‹å§‹ã—ã¾ã™...")

    if not os.path.exists('results'):
        os.makedirs('results')

    all_analyzed_dfs = []

    # --- ä½œå“ã”ã¨ã®åˆ†æãƒ«ãƒ¼ãƒ— ---
    for config in file_config:
        title = config['title']
        path = config['path']
        review_col = config['review_col']
        
        print(f"\n==================== ğŸ“ˆ {title} ã®å‡¦ç†ã‚’é–‹å§‹ ====================")
        
        df = force_read_csv(path)
        if df is None or review_col not in df.columns:
            print(f"ğŸš¨ ã‚¨ãƒ©ãƒ¼: {title}ã®ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã¾ãŸã¯åˆ—å'{review_col}'ã®ç¢ºèªã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue

        df_game = df.copy()
        df_game['Game_Title'] = title 
        df_game = df_game.rename(columns={review_col: 'Original_Review'})
        df_game['Original_Review'] = df_game['Original_Review'].astype(str).str.strip().replace('nan', '')
        df_game = df_game[df_game['Original_Review'].str.len() > 1].reset_index(drop=True)
        game_reviews = df_game['Original_Review'].tolist()
        
        processed_reviews = [preprocess_text(review, mecab) for review in game_reviews]
        
        # æ„Ÿæƒ…åˆ†æã®å®Ÿè¡Œ
        sentiment_results = [analyze_sentiment(words) for words in processed_reviews]
        sentiment_df = pd.DataFrame(sentiment_results, columns=['Sentiment', 'Positive_Score', 'Negative_Score'])

        df_game['Sentiment'] = sentiment_df['Sentiment']
        df_game['Positive_Score'] = sentiment_df['Positive_Score']
        df_game['Negative_Score'] = sentiment_df['Negative_Score']
        
        # æ„Ÿæƒ…æ¥µæ€§ã®åˆ†å¸ƒã‚’å¯è¦–åŒ–
        filename = f'results/{title}_sentiment_distribution_pie_chart.png'
        plot_sentiment_distribution(df_game, filename, title=f'{title} ãƒ¬ãƒ“ãƒ¥ãƒ¼æ„Ÿæƒ…æ¥µæ€§ã®åˆ†å¸ƒ')
        print(f"âœ… æ„Ÿæƒ…åˆ†æçµæœã‚’å††ã‚°ãƒ©ãƒ• '{filename}' ã¨ã—ã¦ä¿å­˜ã—ã¾ã—ãŸã€‚")

        # çµæœã‚’CSVã«ä¿å­˜
        output_path = f'results/{title}_sentiment_analysis_results.csv'
        df_game.to_csv(output_path, index=False, encoding='utf-8')
        print(f"âœ… è©³ç´°çµæœã‚’ '{output_path}' ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

    print("\n--- æ„Ÿæƒ…åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å…¨å‡¦ç†ã‚’å®Œäº†ã—ã¾ã—ãŸ ---")

if __name__ == "__main__":
    main()